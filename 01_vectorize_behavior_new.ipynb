{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de45dae5",
   "metadata": {},
   "source": [
    "**NEW**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c8630a",
   "metadata": {},
   "source": [
    "**Cell 1: Imports**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e50415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json, numpy as np\n",
    "from tqdm import tqdm\n",
    "from ember import PEFeatureExtractor\n",
    "from scipy import sparse as sp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf2bb84",
   "metadata": {},
   "source": [
    "**Cell 2: Paths που δεν εξαρτώνται από username**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4d99abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Paths που δεν εξαρτώνται από username\n",
    "BASE = Path.home() / \"Desktop\" / \"Malware Project\"\n",
    "DATA = BASE / \"data\" / \"behavior\"          # train_features.jsonl / test_features.jsonl\n",
    "TAGS = BASE / \"data\" / \"tags\"              # behavior_train.jsonl / behavior_test.jsonl\n",
    "OUT  = BASE / \"data\" / \"behavior_vectors_paper\"  # εδώ θα γραφτούν τα νέα αρχεία\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91223c3",
   "metadata": {},
   "source": [
    "**Cell 3: Helpers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f47c2535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) helpers\n",
    "def stream_jsonl(fp):\n",
    "    with open(fp, \"r\") as f:\n",
    "        for line in f:\n",
    "            yield json.loads(line)\n",
    "\n",
    "def build_md5_set(tag_fp):\n",
    "    keep = set()\n",
    "    for rec in stream_jsonl(tag_fp):\n",
    "        md5 = rec.get(\"md5\")\n",
    "        if md5:\n",
    "            keep.add(md5)\n",
    "    return keep\n",
    "\n",
    "def vectorize_split(split_name, feat_fp, keep_set, out_dir, chunk_rows=5000):\n",
    "    extractor = PEFeatureExtractor()\n",
    "    X_chunk = []\n",
    "    kept = 0\n",
    "    saved_parts = 0\n",
    "\n",
    "    for meta in tqdm(stream_jsonl(feat_fp), desc=split_name):\n",
    "        md5 = meta.get(\"md5\")\n",
    "        if md5 not in keep_set:\n",
    "            continue\n",
    "        try:\n",
    "            vec = extractor.process_raw_features(meta).astype(np.float32)\n",
    "        except Exception:\n",
    "            continue\n",
    "        X_chunk.append(vec)\n",
    "        kept += 1\n",
    "\n",
    "        if len(X_chunk) >= chunk_rows:\n",
    "            X_csr = sp.csr_matrix(np.vstack(X_chunk))\n",
    "            sp.save_npz(out_dir / f\"{split_name}_part{saved_parts:03d}.npz\", X_csr, compressed=False)\n",
    "            X_chunk = []\n",
    "            saved_parts += 1\n",
    "\n",
    "    if X_chunk:\n",
    "        X_csr = sp.csr_matrix(np.vstack(X_chunk))\n",
    "        sp.save_npz(out_dir / f\"{split_name}_part{saved_parts:03d}.npz\", X_csr, compressed=False)\n",
    "        saved_parts += 1\n",
    "\n",
    "    print(f\"[{split_name}] DONE: kept={kept}, parts={saved_parts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f185e7b9",
   "metadata": {},
   "source": [
    "**Cell 4: Checks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c590348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) checks\n",
    "assert (DATA/\"train_features.jsonl\").exists(), \"Λείπει train_features.jsonl\"\n",
    "assert (DATA/\"test_features.jsonl\").exists(),  \"Λείπει test_features.jsonl\"\n",
    "assert (TAGS/\"behavior_train.jsonl\").exists(), \"Λείπει behavior_train.jsonl\"\n",
    "assert (TAGS/\"behavior_test.jsonl\").exists(),  \"Λείπει behavior_test.jsonl\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d9869d",
   "metadata": {},
   "source": [
    "**Cell 5: Build tag sets and run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "074e8547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 2754289it [48:10, 952.90it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] DONE: kept=2754289, parts=551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 223300it [04:00, 926.80it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] DONE: kept=223300, parts=45\n"
     ]
    }
   ],
   "source": [
    "# 4) build tag sets και τρέξιμο\n",
    "keep_train = build_md5_set(TAGS / \"behavior_train.jsonl\")\n",
    "keep_test  = build_md5_set(TAGS / \"behavior_test.jsonl\")\n",
    "\n",
    "vectorize_split(\"train\", DATA / \"train_features.jsonl\", keep_train, OUT, chunk_rows=5000)\n",
    "vectorize_split(\"test\",  DATA / \"test_features.jsonl\",  keep_test,  OUT, chunk_rows=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1696019b",
   "metadata": {},
   "source": [
    "**Cell 6: Helpers for tags/labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3f9860c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- helpers για tags/labels --\n",
    "\n",
    "def _labels_from_ranking(rec):\n",
    "    \"\"\"Παίρνω τα string labels από το πεδίο 'ranking' ενός tag record.\"\"\"\n",
    "    labs = []\n",
    "    ranking = rec.get(\"ranking\") or []\n",
    "    for it in ranking:\n",
    "        if isinstance(it, (list, tuple)) and it:\n",
    "            labs.append(str(it[0]).lower())\n",
    "        else:\n",
    "            labs.append(str(it).lower())\n",
    "    return labs\n",
    "\n",
    "def build_label_map(train_tag_fp, test_tag_fp):\n",
    "    \"\"\"Μαζεύω ΟΛΑ τα unique labels (behavior tags) -> (all_labels, tag_to_idx).\"\"\"\n",
    "    seen = set()\n",
    "    for fp in (train_tag_fp, test_tag_fp):\n",
    "        with open(fp, \"r\") as f:\n",
    "            for line in f:\n",
    "                rec = json.loads(line)\n",
    "                for lab in _labels_from_ranking(rec):\n",
    "                    seen.add(lab)\n",
    "    all_labels = sorted(seen)\n",
    "    tag_to_idx = {t:i for i,t in enumerate(all_labels)}\n",
    "    return all_labels, tag_to_idx\n",
    "\n",
    "def load_tag_map_for(fp, keep_set):\n",
    "    \"\"\"Διαβάζω tags jsonl και κρατώ ΜΟΝΟ md5 που είναι στο keep_set: md5 -> [labels].\"\"\"\n",
    "    m = {}\n",
    "    with open(fp, \"r\") as f:\n",
    "        for line in f:\n",
    "            rec = json.loads(line)\n",
    "            md5 = rec.get(\"md5\")\n",
    "            if not md5 or md5 not in keep_set:\n",
    "                continue\n",
    "            m[md5] = _labels_from_ranking(rec)\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18080410",
   "metadata": {},
   "source": [
    "**Cell 7: Create Y parts (same filtering with the X parts)** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74a3d3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- φτιάχνω τα Y parts ώστε να ταιριάζουν 1-προς-1 με τα X parts --\n",
    "\n",
    "def build_y_parts(split_name, feat_fp, tags_fp, keep_set, out_dir, tag_to_idx, chunk_rows=5000):\n",
    "    \"\"\"\n",
    "    Ξαναπερνάω το ίδιο features jsonl ΜΕ το ίδιο φίλτρο που χρησιμοποιήσαμε στο vectorize:\n",
    "    - md5 ∈ keep_set\n",
    "    - extractor.process_raw_features(meta) να ΜΗΝ σκάσει (ίδιο try/except)\n",
    "    Κάθε chunk_rows γράφω y_{split}_partXXX.npy (multi-hot).\n",
    "    \"\"\"\n",
    "    extractor = PEFeatureExtractor()\n",
    "    Y_chunk = []\n",
    "    saved_parts = 0\n",
    "    kept = 0\n",
    "\n",
    "    # Για γρήγορο lookup των labels του md5\n",
    "    tag_map = load_tag_map_for(tags_fp, keep_set)  # md5 -> [labels]\n",
    "\n",
    "    with open(feat_fp, \"r\") as f:\n",
    "        for line in tqdm(f, desc=f\"{split_name}-labels\"):\n",
    "            meta = json.loads(line)\n",
    "            md5 = meta.get(\"md5\")\n",
    "            if md5 not in keep_set:\n",
    "                continue\n",
    "            # ίδιο φίλτρο με το X: αν αποτύχει ο extractor, skip ώστε να ταιριάξει η σειρά/πλήθος\n",
    "            try:\n",
    "                _ = extractor.process_raw_features(meta)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            labs = tag_map.get(md5, [])\n",
    "            y = np.zeros(len(tag_to_idx), dtype=np.int8)\n",
    "            for lab in labs:\n",
    "                j = tag_to_idx.get(lab)\n",
    "                if j is not None:\n",
    "                    y[j] = 1\n",
    "            Y_chunk.append(y)\n",
    "            kept += 1\n",
    "\n",
    "            if len(Y_chunk) >= chunk_rows:\n",
    "                np.save(out_dir / f\"y_{split_name}_part{saved_parts:03d}.npy\", np.vstack(Y_chunk))\n",
    "                Y_chunk = []\n",
    "                saved_parts += 1\n",
    "\n",
    "    if Y_chunk:\n",
    "        np.save(out_dir / f\"y_{split_name}_part{saved_parts:03d}.npy\", np.vstack(Y_chunk))\n",
    "        saved_parts += 1\n",
    "\n",
    "    print(f\"[{split_name} labels] DONE: kept={kept}, parts={saved_parts}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f491d0",
   "metadata": {},
   "source": [
    "**Cell 8: Build sets and run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96bc04e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-labels: 2754289it [46:32, 986.35it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train labels] DONE: kept=2754289, parts=551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test-labels: 223300it [03:45, 990.98it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test labels] DONE: kept=223300, parts=45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# build sets (ίδια με πριν)\n",
    "keep_train = build_md5_set(TAGS / \"behavior_train.jsonl\")\n",
    "keep_test  = build_md5_set(TAGS / \"behavior_test.jsonl\")\n",
    "\n",
    "# label map\n",
    "all_tags, tag_to_idx = build_label_map(TAGS / \"behavior_train.jsonl\", TAGS / \"behavior_test.jsonl\")\n",
    "with open(OUT / \"label_map.json\", \"w\") as f:\n",
    "    json.dump({\"labels\": all_tags}, f, indent=2)\n",
    "\n",
    "# y parts (ίδιο chunk_rows με τα X!)\n",
    "build_y_parts(\"train\", DATA / \"train_features.jsonl\", TAGS / \"behavior_train.jsonl\",\n",
    "              keep_train, OUT, tag_to_idx, chunk_rows=5000)\n",
    "\n",
    "build_y_parts(\"test\",  DATA / \"test_features.jsonl\",  TAGS / \"behavior_test.jsonl\",\n",
    "              keep_test,  OUT, tag_to_idx, chunk_rows=5000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ba4a35",
   "metadata": {},
   "source": [
    "**Cell 9: Quick checks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e45abd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts:  551 551 | 45 45\n",
      "[train part 000] rows X=5000, Y=5000\n",
      "[train part 275] rows X=5000, Y=5000\n",
      "[train part 550] rows X=4289, Y=4289\n"
     ]
    }
   ],
   "source": [
    "# Πρέπει να ταιριάζουν πλήθος part-αρχείων και row counts\n",
    "import glob, numpy as np, scipy.sparse as sp\n",
    "\n",
    "train_X = sorted(glob.glob(str(OUT / \"train_part*.npz\")))\n",
    "train_Y = sorted(glob.glob(str(OUT / \"y_train_part*.npy\")))\n",
    "test_X  = sorted(glob.glob(str(OUT / \"test_part*.npz\")))\n",
    "test_Y  = sorted(glob.glob(str(OUT / \"y_test_part*.npy\")))\n",
    "\n",
    "print(\"counts: \", len(train_X), len(train_Y), \"|\", len(test_X), len(test_Y))\n",
    "assert len(train_X) == len(train_Y)\n",
    "assert len(test_X) == len(test_Y)\n",
    "\n",
    "# spot check σε 2-3 ζευγάρια\n",
    "def _rows_X(path): return sp.load_npz(path).shape[0]\n",
    "def _rows_Y(path): return np.load(path).shape[0]\n",
    "\n",
    "for i in [0, len(train_X)//2, len(train_X)-1]:\n",
    "    rx, ry = _rows_X(train_X[i]), _rows_Y(train_Y[i])\n",
    "    print(f\"[train part {i:03d}] rows X={rx}, Y={ry}\")\n",
    "    assert rx == ry\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ember",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
