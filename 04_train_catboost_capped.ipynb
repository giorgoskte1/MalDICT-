{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "becfb19e",
   "metadata": {},
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccad563f",
   "metadata": {},
   "source": [
    "**Cell 1: Imports, Paths, Labels, Part files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe847f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded labels: 64\n",
      "adware, antiav, antifw, autorun, backdoor, banker, bho, binder, blocker, bundler ...\n",
      "Train parts (X): 551 | Train parts (Y_cap): 551\n",
      "Test  parts (X): 45 | Test  parts (Y): 45\n",
      "[train part 0] rows X=2851, Y=2851\n",
      "[test  part 0] rows X=12,  Y=12\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from glob import glob\n",
    "import re\n",
    "\n",
    "# Paths (ίδια λογική με τα άλλα notebooks)\n",
    "BASE = Path.home() / \"Desktop\" / \"Malware Project\"\n",
    "VEC  = BASE / \"data\" / \"behavior_vectors_paper\"\n",
    "\n",
    "# Models & results folders για CatBoost\n",
    "MODELS_DIR  = VEC / \"models_catboost_capped\"\n",
    "RESULTS_DIR = VEC / \"results_catboost_capped_eval\"\n",
    "MODELS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "RESULTS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Φόρτωση label names (προτιμούμε label_map_balanced.json αν υπάρχει)\n",
    "label_map_paths = [\n",
    "    VEC / \"label_map_balanced.json\",\n",
    "    VEC / \"label_map.json\",\n",
    "]\n",
    "\n",
    "label_names = None\n",
    "for p in label_map_paths:\n",
    "    if p.exists():\n",
    "        with open(p, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        if isinstance(data, dict) and \"labels\" in data:\n",
    "            label_names = data[\"labels\"]\n",
    "            break\n",
    "\n",
    "if label_names is None:\n",
    "    raise FileNotFoundError(\"Δεν βρέθηκε ούτε label_map_balanced.json ούτε label_map.json στο VEC.\")\n",
    "\n",
    "n_labels = len(label_names)\n",
    "print(f\"Loaded labels: {n_labels}\")\n",
    "print(\", \".join(label_names[:10]) + (\" ...\" if n_labels > 10 else \"\"))\n",
    "\n",
    "# Train/Test parts: X CAPPED + Y BALANCED (όπως σε RF & XGB)\n",
    "XTRN = sorted(map(Path, glob(str(VEC / \"train_part_capped*.npz\"))))\n",
    "YTRN_CAP = sorted(map(Path, glob(str(VEC / \"y_train_part_capped*.npy\"))))\n",
    "\n",
    "# Load TEST parts: match capped X με balanced Y using part indexes\n",
    "def _index_from_name(p: Path) -> int:\n",
    "    m = re.search(r'(\\d+)$', p.stem)\n",
    "    if not m:\n",
    "        raise ValueError(f\"No trailing index found in filename: {p.name}\")\n",
    "    return int(m.group(1))\n",
    "\n",
    "XTE = sorted(map(Path, glob(str(VEC / \"test_part_capped*.npz\"))))\n",
    "idx_te = [_index_from_name(p) for p in XTE]\n",
    "\n",
    "all_YTE = list(map(Path, glob(str(VEC / \"y_test_part_capped*.npy\"))))\n",
    "map_Y = {_index_from_name(p): p for p in all_YTE}\n",
    "\n",
    "YTE = [map_Y[i] for i in idx_te if i in map_Y]\n",
    "\n",
    "print(\"Train parts (X):\", len(XTRN), \"| Train parts (Y_cap):\", len(YTRN_CAP))\n",
    "print(\"Test  parts (X):\", len(XTE),  \"| Test  parts (Y):\", len(YTE))\n",
    "\n",
    "# Έλεγχος row counts\n",
    "def _rows_X(path): return sp.load_npz(path).shape[0]\n",
    "def _rows_Y(path): return np.load(path, allow_pickle=False).shape[0]\n",
    "\n",
    "assert len(XTRN) == len(YTRN_CAP), \"Αναντιστοιχία train X με y_train_part_capped*.npy\"\n",
    "\n",
    "print(f\"[train part 0] rows X={_rows_X(XTRN[0])}, Y={_rows_Y(YTRN_CAP[0])}\")\n",
    "print(f\"[test  part 0] rows X={_rows_X(XTE[0])},  Y={_rows_Y(YTE[0])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cab57d",
   "metadata": {},
   "source": [
    "**Cell 2: Assemble X_train, Y_train (sparse), test parts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed08ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1233020, 2381) | Y_train: (1233020, 64)\n",
      "Loaded 45 test X parts & 45 test Y parts\n",
      " Multi-label data loaded correctly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# Train X (sparse)\n",
    "X_train = sp.vstack([sp.load_npz(p) for p in XTRN]).tocsr()\n",
    "\n",
    "# Train Y (multi-label, shape = [N, n_labels])\n",
    "Y_train = np.concatenate([np.load(p, allow_pickle=False) for p in YTRN_CAP])\n",
    "print(\"X_train:\", X_train.shape, \"| Y_train:\", Y_train.shape)\n",
    "\n",
    "# Test parts (κρατάμε σε λίστες όπως στα άλλα notebooks)\n",
    "X_test_parts = [sp.load_npz(p).tocsr() for p in XTE]\n",
    "Y_test_parts = [np.load(p, allow_pickle=False) for p in YTE]\n",
    "\n",
    "print(\"Loaded\", len(X_test_parts), \"test X parts &\", len(Y_test_parts), \"test Y parts\")\n",
    "\n",
    "# sanity checks\n",
    "assert Y_train.shape[1] == len(label_names)\n",
    "for Xt, Yt in zip(X_test_parts, Y_test_parts):\n",
    "    assert Xt.shape[0] == Yt.shape[0]\n",
    "    assert Yt.shape[1] == len(label_names)\n",
    "\n",
    "print(\" Multi-label data loaded correctly.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0bb69b",
   "metadata": {},
   "source": [
    "**Cell 3: Parameters & Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22c1828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 64 label-wise CatBoost models with balanced undersampling...\n",
      "\n",
      "[label 00] 'adware' balanced counts: Counter({np.int64(0): 145064, np.int64(1): 72532}) (train on 217596 samples)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 74\u001b[39m\n\u001b[32m     72\u001b[39m model = CatBoostClassifier(**base_params)\n\u001b[32m     73\u001b[39m t0 = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_sub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_sub\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m dt = time.time() - t0\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# save μοντέλο\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/maltrain/lib/python3.12/site-packages/catboost/core.py:5245\u001b[39m, in \u001b[36mCatBoostClassifier.fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   5242\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[32m   5243\u001b[39m     CatBoostClassifier._check_is_compatible_loss(params[\u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m5245\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5246\u001b[39m \u001b[43m          \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5247\u001b[39m \u001b[43m          \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5248\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/maltrain/lib/python3.12/site-packages/catboost/core.py:2410\u001b[39m, in \u001b[36mCatBoost._fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   2407\u001b[39m allow_clear_pool = train_params[\u001b[33m\"\u001b[39m\u001b[33mallow_clear_pool\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   2409\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[33m'\u001b[39m\u001b[33mTraining plots\u001b[39m\u001b[33m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m.get_params())]):\n\u001b[32m-> \u001b[39m\u001b[32m2410\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval_sets\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2415\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minit_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2416\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2418\u001b[39m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[32m   2419\u001b[39m loss = \u001b[38;5;28mself\u001b[39m._object._get_loss_function_name()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/maltrain/lib/python3.12/site-packages/catboost/core.py:1790\u001b[39m, in \u001b[36m_CatBoostBase._train\u001b[39m\u001b[34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[32m-> \u001b[39m\u001b[32m1790\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_trained_model_attributes()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5023\u001b[39m, in \u001b[36m_catboost._CatBoost._train\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5072\u001b[39m, in \u001b[36m_catboost._CatBoost._train\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from collections import Counter\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def cat_model_path(li: int):\n",
    "    return MODELS_DIR / f\"cat_label_{li:02d}.cbm\"\n",
    "\n",
    "base_params = dict(\n",
    "    loss_function=\"Logloss\",\n",
    "    eval_metric=\"AUC\",\n",
    "    iterations=300,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    l2_leaf_reg=3.0,\n",
    "    random_seed=42,\n",
    "    bootstrap_type=\"Bernoulli\",\n",
    "    subsample=0.8,\n",
    "    thread_count=-1,\n",
    "    verbose=False,\n",
    "    task_type=\"CPU\",\n",
    ")\n",
    "\n",
    "n_labels = Y_train.shape[1]\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Training {n_labels} label-wise CatBoost models with balanced undersampling...\")\n",
    "\n",
    "train_stats = []\n",
    "total_start = time.time()\n",
    "trained = 0\n",
    "skipped = 0\n",
    "\n",
    "for li in range(n_labels):\n",
    "    label_name = label_names[li] if li < len(label_names) else f\"label_{li}\"\n",
    "    y_col = Y_train[:, li].astype(int)\n",
    "    cls = np.unique(y_col)\n",
    "\n",
    "    # αν δεν υπάρχουν και οι 2 κλάσεις -> skip\n",
    "    if len(cls) < 2:\n",
    "        print(f\"[label {li:02d}] '{label_name}': only class {cls[0]} -> skip\")\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    # balanced undersampling (1 : 2)\n",
    "    pos_idx = np.where(y_col == 1)[0]\n",
    "    neg_idx = np.where(y_col == 0)[0]\n",
    "    n_pos = len(pos_idx)\n",
    "\n",
    "    # προστασία\n",
    "    if n_pos == 0:\n",
    "        print(f\"[label {li:02d}] '{label_name}': no positives -> skip\")\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    neg_sample_size = min(len(neg_idx), n_pos * 2)\n",
    "    neg_sample_idx = np.random.choice(neg_idx, size=neg_sample_size, replace=False)\n",
    "\n",
    "    sel_idx = np.concatenate([pos_idx, neg_sample_idx])\n",
    "    np.random.shuffle(sel_idx)\n",
    "\n",
    "    X_sub = X_train[sel_idx]\n",
    "    y_sub = y_col[sel_idx]\n",
    "\n",
    "    counts = Counter(y_sub)\n",
    "    print(f\"\\n[label {li:02d}] '{label_name}' balanced counts: {counts} \"\n",
    "          f\"(train on {len(sel_idx)} samples)\")\n",
    "\n",
    "    model = CatBoostClassifier(**base_params)\n",
    "    t0 = time.time()\n",
    "    model.fit(X_sub, y_sub)\n",
    "    dt = time.time() - t0\n",
    "\n",
    "    # save μοντέλο\n",
    "    mpath = cat_model_path(li)\n",
    "    model.save_model(mpath)\n",
    "    print(f\"    saved -> {mpath.name} ({dt:.1f}s)\")\n",
    "    trained += 1\n",
    "\n",
    "    train_stats.append({\n",
    "        \"label_index\": li,\n",
    "        \"label_name\": label_name,\n",
    "        \"n_pos_total\": int((y_col == 1).sum()),\n",
    "        \"n_neg_total\": int((y_col == 0).sum()),\n",
    "        \"n_train_used\": int(len(sel_idx)),\n",
    "        \"train_time_sec\": float(dt),\n",
    "    })\n",
    "\n",
    "total_time = time.time() - total_start\n",
    "print(f\"\\n Trained {trained} models, skipped {skipped}.\")\n",
    "print(f\"Total CatBoost training time: {total_time:.1f} sec\")\n",
    "\n",
    "train_stats_df = pd.DataFrame(train_stats)\n",
    "train_stats_df.to_csv(RESULTS_DIR / \"catboost_training_stats.csv\", index=False)\n",
    "print(\"Saved training stats -> catboost_training_stats.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9440914",
   "metadata": {},
   "source": [
    "**Cell 4: Evaluate Test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223c6a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] part 1/45 done\n",
      "[test] part 2/45 done\n",
      "[test] part 3/45 done\n",
      "[test] part 4/45 done\n",
      "[test] part 5/45 done\n",
      "[test] part 6/45 done\n",
      "[test] part 7/45 done\n",
      "[test] part 8/45 done\n",
      "[test] part 9/45 done\n",
      "[test] part 10/45 done\n",
      "[test] part 11/45 done\n",
      "[test] part 12/45 done\n",
      "[test] part 13/45 done\n",
      "[test] part 14/45 done\n",
      "[test] part 15/45 done\n",
      "[test] part 16/45 done\n",
      "[test] part 17/45 done\n",
      "[test] part 18/45 done\n",
      "[test] part 19/45 done\n",
      "[test] part 20/45 done\n",
      "[test] part 21/45 done\n",
      "[test] part 22/45 done\n",
      "[test] part 23/45 done\n",
      "[test] part 24/45 done\n",
      "[test] part 25/45 done\n",
      "[test] part 26/45 done\n",
      "[test] part 27/45 done\n",
      "[test] part 28/45 done\n",
      "[test] part 29/45 done\n",
      "[test] part 30/45 done\n",
      "[test] part 31/45 done\n",
      "[test] part 32/45 done\n",
      "[test] part 33/45 done\n",
      "[test] part 34/45 done\n",
      "[test] part 35/45 done\n",
      "[test] part 36/45 done\n",
      "[test] part 37/45 done\n",
      "[test] part 38/45 done\n",
      "[test] part 39/45 done\n",
      "[test] part 40/45 done\n",
      "[test] part 41/45 done\n",
      "[test] part 42/45 done\n",
      "[test] part 43/45 done\n",
      "[test] part 44/45 done\n",
      "[test] part 45/45 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/maltrain/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/maltrain/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/maltrain/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/maltrain/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/maltrain/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/maltrain/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/maltrain/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/maltrain/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Micro</th>\n",
       "      <th>Macro</th>\n",
       "      <th>Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.1560</td>\n",
       "      <td>0.2296</td>\n",
       "      <td>0.2794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.4438</td>\n",
       "      <td>0.4369</td>\n",
       "      <td>0.4438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-score</th>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.2535</td>\n",
       "      <td>0.2955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.8320</td>\n",
       "      <td>0.8357</td>\n",
       "      <td>0.7898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Micro   Macro  Weighted\n",
       "Precision  0.1560  0.2296    0.2794\n",
       "Recall     0.4438  0.4369    0.4438\n",
       "F1-score   0.2309  0.2535    0.2955\n",
       "AUC        0.8320  0.8357    0.7898"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CatBoost test summary -> /Users/georgektenas/Desktop/Malware Project/data/behavior_vectors_paper/results_catboost_capped_eval/overall_metrics_catboost_capped_multi_label.csv /Users/georgektenas/Desktop/Malware Project/data/behavior_vectors_paper/results_catboost_capped_eval/overall_metrics_catboost_capped_multi_label.json\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "n_labels = Y_train.shape[1]\n",
    "\n",
    "def model_path_for(li: int):\n",
    "    return MODELS_DIR / f\"cat_label_{li:02d}.cbm\"\n",
    "\n",
    "# αν έχεις thresholds από tuning για CatBoost, φόρτωσέ τα εδώ\n",
    "USE_THRESHOLDS = False\n",
    "if USE_THRESHOLDS:\n",
    "    THRESH_PATH = RESULTS_DIR / \"catboost_label_thresholds.json\"\n",
    "    with open(THRESH_PATH) as f:\n",
    "        thr_info = json.load(f)\n",
    "    thr_map = {int(k): float(v) for k, v in thr_info[\"thresholds\"].items()}\n",
    "else:\n",
    "    thr_map = {}\n",
    "\n",
    "y_true_all, y_prob_all, y_pred_all = [], [], []\n",
    "\n",
    "for i, (Xt, Yt) in enumerate(zip(X_test_parts, Y_test_parts), start=1):\n",
    "    Xt = Xt.tocsr()\n",
    "    Yt = Yt.astype(np.int8)\n",
    "\n",
    "    probs = np.zeros_like(Yt, dtype=np.float32)\n",
    "    preds = np.zeros_like(Yt, dtype=np.int8)\n",
    "\n",
    "    for li in range(n_labels):\n",
    "        mpath = model_path_for(li)\n",
    "        if not mpath.exists():\n",
    "            continue\n",
    "\n",
    "        model = CatBoostClassifier()\n",
    "        model.load_model(str(mpath))\n",
    "\n",
    "        p = model.predict_proba(Xt)[:, 1]\n",
    "        probs[:, li] = p\n",
    "\n",
    "        thr = thr_map.get(li, 0.5)\n",
    "        preds[:, li] = (p >= thr).astype(np.int8)\n",
    "\n",
    "    y_true_all.append(Yt)\n",
    "    y_prob_all.append(probs)\n",
    "    y_pred_all.append(preds)\n",
    "    print(f\"[test] part {i}/{len(X_test_parts)} done\")\n",
    "\n",
    "y_true = np.vstack(y_true_all)\n",
    "y_prob = np.vstack(y_prob_all)\n",
    "y_pred = np.vstack(y_pred_all)\n",
    "\n",
    "# metrics\n",
    "p_micro, r_micro, f1_micro, _ = precision_recall_fscore_support(\n",
    "    y_true, y_pred, average=\"micro\", zero_division=0\n",
    ")\n",
    "p_macro, r_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "    y_true, y_pred, average=\"macro\", zero_division=0\n",
    ")\n",
    "p_w, r_w, f1_w, _ = precision_recall_fscore_support(\n",
    "    y_true, y_pred, average=\"weighted\", zero_division=0\n",
    ")\n",
    "\n",
    "try:\n",
    "    auc_micro = roc_auc_score(y_true, y_prob, average=\"micro\")\n",
    "except ValueError:\n",
    "    auc_micro = np.nan\n",
    "\n",
    "auc_per_label = []\n",
    "for li in range(n_labels):\n",
    "    y = y_true[:, li]\n",
    "    s = y_prob[:, li]\n",
    "    if np.unique(y).size == 2:\n",
    "        try:\n",
    "            auc_per_label.append(roc_auc_score(y, s))\n",
    "        except ValueError:\n",
    "            pass\n",
    "auc_macro = float(np.nanmean(auc_per_label)) if auc_per_label else np.nan\n",
    "\n",
    "try:\n",
    "    auc_weighted = roc_auc_score(y_true, y_prob, average=\"weighted\")\n",
    "except ValueError:\n",
    "    auc_weighted = np.nan\n",
    "\n",
    "summary = pd.DataFrame(\n",
    "    {\n",
    "        \"Micro\":    [p_micro, r_micro, f1_micro, auc_micro],\n",
    "        \"Macro\":    [p_macro, r_macro, f1_macro, auc_macro],\n",
    "        \"Weighted\": [p_w,     r_w,     f1_w,     auc_weighted],\n",
    "    },\n",
    "    index=[\"Precision\", \"Recall\", \"F1-score\", \"AUC\"],\n",
    ").round(4)\n",
    "\n",
    "display(summary)\n",
    "\n",
    "OUT_PATH_CSV  = RESULTS_DIR / \"overall_metrics_catboost_capped_multi_label.csv\"\n",
    "OUT_PATH_JSON = RESULTS_DIR / \"overall_metrics_catboost_capped_multi_label.json\"\n",
    "summary.to_csv(OUT_PATH_CSV)\n",
    "summary.to_json(OUT_PATH_JSON, orient=\"index\", indent=2)\n",
    "print(\"Saved CatBoost test summary ->\", OUT_PATH_CSV, OUT_PATH_JSON)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126891bc",
   "metadata": {},
   "source": [
    "**Cell 5: Per-label β-tuning (thresholds) + tuned global metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02a94de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching best threshold per label (maximize per-label F1)...\n",
      "Computed thresholds for 55 labels.\n",
      "Saved thresholds -> /Users/georgektenas/Desktop/Malware Project/data/behavior_vectors_paper/results_catboost_capped_eval/catboost_label_thresholds.json\n",
      "\n",
      "=== CatBoost Tuned (per-label β) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/maltrain/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/maltrain/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/maltrain/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/maltrain/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/maltrain/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/maltrain/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/maltrain/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/maltrain/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Micro</th>\n",
       "      <th>Macro</th>\n",
       "      <th>Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.2389</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.4697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.4522</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.4522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-score</th>\n",
       "      <td>0.3127</td>\n",
       "      <td>0.3851</td>\n",
       "      <td>0.4104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.8320</td>\n",
       "      <td>0.8357</td>\n",
       "      <td>0.7898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Micro   Macro  Weighted\n",
       "Precision  0.2389  0.4404    0.4697\n",
       "Recall     0.4522  0.4500    0.4522\n",
       "F1-score   0.3127  0.3851    0.4104\n",
       "AUC        0.8320  0.8357    0.7898"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tuned summary -> overall_metrics_catboost_capped_tuned_beta.(csv/json)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "# πρέπει να υπάρχουν από το Cell 4\n",
    "assert \"y_true\" in globals() and \"y_prob\" in globals(), \"Run Cell 4 first.\"\n",
    "\n",
    "n_labels = y_true.shape[1]\n",
    "beta_grid = np.arange(0.05, 0.96, 0.01)\n",
    "\n",
    "best_thr = {}\n",
    "\n",
    "print(\"Searching best threshold per label (maximize per-label F1)...\")\n",
    "\n",
    "for li in range(n_labels):\n",
    "    y_true_li = y_true[:, li]\n",
    "\n",
    "    # skip labels χωρίς και τις δύο κλάσεις\n",
    "    if y_true_li.max() == y_true_li.min():\n",
    "        continue\n",
    "\n",
    "    probs_li = y_prob[:, li]\n",
    "\n",
    "    best_f1 = -1.0\n",
    "    best_b = 0.5\n",
    "\n",
    "    for b in beta_grid:\n",
    "        y_pred_li = (probs_li >= b).astype(int)\n",
    "        _, _, f1_li, _ = precision_recall_fscore_support(\n",
    "            y_true_li, y_pred_li, average=\"binary\", zero_division=0\n",
    "        )\n",
    "        if f1_li > best_f1:\n",
    "            best_f1 = f1_li\n",
    "            best_b = float(b)\n",
    "\n",
    "    best_thr[li] = best_b\n",
    "\n",
    "print(f\"Computed thresholds for {len(best_thr)} labels.\")\n",
    "\n",
    "# --- Save thresholds σε json ---\n",
    "\n",
    "thr_out = {\n",
    "    \"description\": \"Per-label thresholds for CatBoost (capped, multi-label), tuned to maximize per-label F1.\",\n",
    "    \"thresholds\": {str(k): float(v) for k, v in best_thr.items()},\n",
    "}\n",
    "thr_path = RESULTS_DIR / \"catboost_label_thresholds.json\"\n",
    "with open(thr_path, \"w\") as f:\n",
    "    json.dump(thr_out, f, indent=2)\n",
    "print(\"Saved thresholds ->\", thr_path)\n",
    "\n",
    "# --- Global tuned metrics ---\n",
    "\n",
    "# φτιάχνουμε vector thresholds, default 0.5 όπου δεν υπάρχει τιμή\n",
    "thr_vec = np.array([best_thr.get(li, 0.5) for li in range(n_labels)], dtype=float)\n",
    "\n",
    "y_pred_tuned = (y_prob >= thr_vec[None, :]).astype(int)\n",
    "\n",
    "# micro / macro / weighted\n",
    "p_micro, r_micro, f1_micro, _ = precision_recall_fscore_support(\n",
    "    y_true, y_pred_tuned, average=\"micro\", zero_division=0\n",
    ")\n",
    "p_macro, r_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "    y_true, y_pred_tuned, average=\"macro\", zero_division=0\n",
    ")\n",
    "p_w, r_w, f1_w, _ = precision_recall_fscore_support(\n",
    "    y_true, y_pred_tuned, average=\"weighted\", zero_division=0\n",
    ")\n",
    "\n",
    "# AUC (micro & weighted όπως πριν)\n",
    "try:\n",
    "    auc_micro = roc_auc_score(y_true, y_prob, average=\"micro\")\n",
    "except ValueError:\n",
    "    auc_micro = np.nan\n",
    "\n",
    "try:\n",
    "    auc_w = roc_auc_score(y_true, y_prob, average=\"weighted\")\n",
    "except ValueError:\n",
    "    auc_w = np.nan\n",
    "\n",
    "# Macro AUC: μέσος όρος μόνο από labels με και τις δύο κλάσεις\n",
    "auc_labels = []\n",
    "for li in range(n_labels):\n",
    "    y_li = y_true[:, li]\n",
    "    if y_li.max() == y_li.min():\n",
    "        continue  # skip labels χωρίς 0/1\n",
    "    try:\n",
    "        auc_li = roc_auc_score(y_li, y_prob[:, li])\n",
    "        auc_labels.append(auc_li)\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "auc_macro = float(np.mean(auc_labels)) if auc_labels else np.nan\n",
    "\n",
    "tuned_summary = pd.DataFrame(\n",
    "    {\n",
    "        \"Micro\":    [p_micro, r_micro, f1_micro, auc_micro],\n",
    "        \"Macro\":    [p_macro, r_macro, f1_macro, auc_macro],\n",
    "        \"Weighted\": [p_w,     r_w,     f1_w,     auc_w],\n",
    "    },\n",
    "    index=[\"Precision\", \"Recall\", \"F1-score\", \"AUC\"],\n",
    ").round(4)\n",
    "\n",
    "print(\"\\n=== CatBoost Tuned (per-label β) ===\")\n",
    "display(tuned_summary)\n",
    "\n",
    "# save\n",
    "tuned_summary.to_csv(\n",
    "    RESULTS_DIR / \"overall_metrics_catboost_capped_tuned_beta.csv\"\n",
    ")\n",
    "tuned_summary.to_json(\n",
    "    RESULTS_DIR / \"overall_metrics_catboost_capped_tuned_beta.json\",\n",
    "    orient=\"index\",\n",
    "    indent=2\n",
    ")\n",
    "\n",
    "print(\"Saved tuned summary -> overall_metrics_catboost_capped_tuned_beta.(csv/json)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maltrain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
